# 结构
## 注意力机制
疑问：为什么Q， K， V有独特的含义，不都是从输入经过线性变换得到的吗？

在 Transformer 中，Q、K、V 都是由输入向量通过不同的线性变换得到的。
如果这些线性变换（即 $W_Q$, $W_K$, $W_V$）的参数在初始化时完全相同，那么第一次前向传播时，Q、K、V 的数值几乎是相同的。

$attention$ 公式（即 $softmax(Q·Kᵀ / √dₖ)$· V）将它们组合成注意力输出。
而模型在包含注意力机制的情况下，会在反向传播时，根据损失函数计算出的梯度，分别更新 
$W_Q$, $W_K$, $W_V$	​，从而让这三种线性映射在多次训练迭代后，逐渐学习出不同的功能与语义：

$W_Q$: 学会提取“查询特征”，即要找谁；

​$W_K$: 学会提取“匹配特征”，即别人能被谁找到;
​
$W_V$: 学会提取“内容特征”，即别人提供什么信息。

所以，Q、K、V 的不同含义不是公式内置的，而是训练中逐步形成的。

## Encoder
负责将输入序列转换为高维的上下文感知表示

内部结构包括：

输入 -> 位置编码 -> 多头注意力 -> 残差连接+归一化 -> 前馈MLP -> 残差连接+归一化 -> 输出

一个Encoder层通常会堆叠几层这样的结构

